import cv2
import numpy as np

# Load YOLO model
net = cv2.dnn.readNet("yolov3.weights", "yolov3.cfg")  # Download YOLO weights and cfg files
layer_names = net.getUnconnectedOutLayersNames()

# Load video
cap = cv2.VideoCapture("sample_video.mp4")  # Replace with your video file

# Object tracking using Kalman filter
class KalmanFilter:
    def __init__(self, initial_state):
        self.kalman = cv2.KalmanFilter(4, 2)
        self.kalman.measurementMatrix = np.array([[1, 0, 0, 0],
                                                  [0, 1, 0, 0]], dtype=np.float32)
        self.kalman.transitionMatrix = np.array([[1, 0, 1, 0],
                                                 [0, 1, 0, 1],
                                                 [0, 0, 1, 0],
                                                 [0, 0, 0, 1]], dtype=np.float32)
        self.kalman.processNoiseCov = 1e-5 * np.eye(4)
        self.kalman.measurementNoiseCov = 1e-3 * np.eye(2)
        self.kalman.statePost = np.array(initial_state, dtype=np.float32)

    def update(self, measurement):
        prediction = self.kalman.predict()
        correction = self.kalman.correct(measurement)
        return correction

# Initialize Kalman filter for object tracking
kalman_filters = {}

while True:
    ret, frame = cap.read()
    if not ret:
        break

    height, width, _ = frame.shape

    # YOLO object detection
    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    net.setInput(blob)
    outs = net.forward(layer_names)

    # Object tracking using Kalman filter
    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5:
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)

                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                # Kalman filter initialization
                if class_id not in kalman_filters:
                    kalman_filters[class_id] = KalmanFilter([x, y, w, h])

                # Update Kalman filter with measurement
                measurement = np.array([center_x, center_y], dtype=np.float32)
                kalman_filters[class_id].update(measurement)

                # Get corrected state from Kalman filter
                corrected_state = kalman_filters[class_id].kalman.statePost
                x, y, w, h = corrected_state

                # Draw bounding box and label
                color = (0, 255, 0)  # Green color
                cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), color, 2)
                label = f"Class {class_id}"
                cv2.putText(frame, label, (int(x), int(y) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Display the frame
    cv2.imshow("Object Detection and Tracking", frame)

    # Break the loop if 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture object and close the OpenCV windows
cap.release()
cv2.destroyAllWindows()
